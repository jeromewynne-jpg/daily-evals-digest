# AI Evaluation Papers Digest - 2025-12-09

## Table of Contents
- [HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs](#hallushift-bridging-language-and-vision-through-internal-representation-shifts-for-hierarchical-hallucinations-in-mllms)

---

## [HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs](https://arxiv.org/abs/2512.07687v1)

**Authors & Affiliations**: Sujoy Nath, Arkaprabha Basu, Sharanya Dasgupta are affiliated with Netaji Subhash Engineering College (NSEC), Kolkata, India and TCG Crest, Kolkata, India. Swagatam Das is affiliated with the Electronics and Communication Sciences Unit (ECSU), Indian Statistical Institute, Kolkata, India.

**Models Tested**: Llama-3.2-11B-Vision-Instruct, Llama-3.2-11B-Vision (Meta), PaliGemma-3B-Mix-224 (Google), Kosmos-2-Patch14-224, InstructBLIP-Vicuna-7B, Phi-3.5-Vision-Instruct (Microsoft), Qwen2.5-VL-3B-Instruct (Alibaba), LLaVA-1.5-7B-HF. Also tested LLMs: OPT-6.7B and LLaMA-2-7B (Meta).

**Research Question**: How can hallucinations in Multimodal Large Language Models (MLLMs) be detected through internal representation analysis without relying on external LLM evaluators? Can these hallucinations be categorized hierarchically into category, attribute, and relation types?

**Claim**: HALLUSHIFT++ extends hallucination detection from text-only LLMs to MLLMs by analyzing internal layer dynamics (cross-layer inconsistency, attention dispersion, confidence degradation), introducing 74 features total (62 from HALLUSHIFT + 12 novel features) and semantic chunking to enable hierarchical classification of hallucination types rather than binary detection, achieving up to 64.12% improvement in AUC-ROC over HALLUSHIFT.

**Method**: The framework extracts 74-dimensional features from internal model states (hidden states, attention weights, token probabilities), including novel attention concentration features (Gini coefficients), layer consistency features (cross-layer disagreement), and perplexity/confidence features. Semantic chunking decomposes generated text into object, attribute, and relation chunks using NLP techniques (POS tagging, NER, dependency parsing). A membership function with attention mechanisms assigns probabilistic scores across four classes: Correct, Category, Attribute, and Relation hallucinations.

**Results**: HALLUSHIFT++ achieved 27.7-64.1% AUC-ROC improvements across all tested MLLMs on MS-COCO and LLaVA datasets compared to HALLUSHIFT. Best performance: LLaVA-1.5-7B-HF (96.5% AUC-ROC), Llama-3.2-11B-Vision (91.7% AUC-ROC). On text-only LLM tasks, achieved ~3% improvement over HALLUSHIFT (92.68% vs 89.91% on OPT-6.7B TruthfulQA). Feature importance analysis showed Chunk Relative Position (0.2142) and Total Chunks per Image (0.0309) as most important features.

**Limitations**: The paper relies on manual ground truth annotation which may introduce subjective biases. The semantic chunking approach depends heavily on NLP tools that may fail on complex sentence structures. The method requires access to internal model representations, limiting applicability to black-box models. Class imbalance issues are addressed with SMOTE and class weighting but attribute hallucinations still constitute less than 5% of samples, potentially affecting generalization. The evaluation is limited to specific benchmarks (MS-COCO, LLaVA) and may not generalize to other domains or languages.

---

*Generated with [Claude Code](https://claude.ai/code)*
